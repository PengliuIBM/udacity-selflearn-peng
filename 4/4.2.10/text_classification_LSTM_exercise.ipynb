{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification using LSTM\n",
    "\n",
    "In this coding exercise, you will create a simple LSTM model using PyTorch to perform text classification on a dataset of short phrases. Your task is to fill in the missing parts of the code marked with `# TODO`.\n",
    "\n",
    "You need to:\n",
    "\n",
    "- Create a vocabulary to represent words as indices.\n",
    "- Tokenize, encode, and pad the phrases.\n",
    "- Convert the phrases and categories to PyTorch tensors.\n",
    "- Instantiate the LSTM model with the vocabulary size, embedding dimensions, hidden dimensions, and output dimensions.\n",
    "- Define the loss function and optimizer.\n",
    "- Train the model for a number of epochs.\n",
    "- Test the model on new phrases and print the category predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases (textual data) and their category labels (0 for sports, 1 for technology, 2 for food)\n",
    "# Note: this data is extremely less for realistically training an LSTM model. Feel free to use\n",
    "# a relevant data source or create your own dummy data for this exercise.\n",
    "phrases = [\"great goal scored\", \"amazing touchdown\", \"new phone release\", \"latest laptop model\", \"tasty pizza\", \"delicious burger\"]\n",
    "categories = [0, 0, 1, 1, 2, 2]\n",
    "\n",
    "# TODO: Create a vocabulary to represent words as indices\n",
    "# Create a vocabulary to represent words as indices\n",
    "vocab = {\"<PAD>\": 0, \"great\": 1, \"goal\": 2, \"scored\": 3, \"amazing\": 4, \"touchdown\": 5, \"new\": 6, \"phone\": 7, \"release\": 8, \"latest\": 9, \"laptop\": 10, \"model\": 11, \"tasty\": 12, \"pizza\": 13, \"delicious\": 14, \"burger\": 15}\n",
    "\n",
    "# TODO: Tokenize, encode, and pad phrases\n",
    "# Tokenize, encode, and pad phrases\n",
    "encoded_phrases = [[vocab[word] for word in phrase.split()] for phrase in phrases]\n",
    "max_length = max([len(phrase) for phrase in encoded_phrases])\n",
    "padded_phrases = [phrase + [vocab[\"<PAD>\"]] * (max_length - len(phrase)) for phrase in encoded_phrases]\n",
    "\n",
    "# TODO: Convert phrases and categories to PyTorch tensors\n",
    "# Convert phrases and categories to PyTorch tensors\n",
    "inputs = torch.LongTensor(padded_phrases)\n",
    "labels = torch.LongTensor(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "class PhraseClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(PhraseClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, _) = self.lstm(embedded)\n",
    "        logits = self.fc(hidden.squeeze(0))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.346204549074173\n",
      "Epoch: 200, Loss: 0.043716758489608765\n",
      "Epoch: 300, Loss: 0.01583930291235447\n",
      "Epoch: 400, Loss: 0.008529440499842167\n",
      "Epoch: 500, Loss: 0.005532508250325918\n",
      "Epoch: 600, Loss: 0.003964465111494064\n",
      "Epoch: 700, Loss: 0.0030175100546330214\n",
      "Epoch: 800, Loss: 0.0023911702446639538\n",
      "Epoch: 900, Loss: 0.0019502732902765274\n",
      "Epoch: 1000, Loss: 0.0016255333321169019\n",
      "Test predictions: tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Instantiate model and define loss and optimizer\n",
    "# Instantiate model and define loss and optimizer\n",
    "model = PhraseClassifier(len(vocab), embedding_dim=10, hidden_dim=20, output_dim=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# TODO: Train the model for a number of epochs\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(inputs.t())\n",
    "    loss = criterion(predictions, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")\n",
    "# TODO: Test the model on new phrases\n",
    "# Test the model on new phrases\n",
    "with torch.no_grad():\n",
    "    test_phrases = [\"incredible match\", \"newest gadget\", \"yummy cake\"]\n",
    "    encoded_test_phrases = [[vocab.get(word, vocab[\"<PAD>\"]) for word in phrase.split()] for phrase in test_phrases]\n",
    "    padded_test_phrases = [phrase + [vocab[\"<PAD>\"]] * (max_length - len(phrase)) for phrase in encoded_test_phrases]\n",
    "    test_inputs = torch.LongTensor(padded_test_phrases)\n",
    "    test_predictions = torch.argmax(model(test_inputs.t()), dim=1)\n",
    "    print(\"Test predictions:\", test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
